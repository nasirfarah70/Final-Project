{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMSkillsNetworkBD0231ENCoursera2789-2023-01-01\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project - Build an ML Pipeline for Airfoil noise prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **90** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are a data engineer at an aeronautics consulting company. Your company prides itself in being able to efficiently design airfoils for use in planes and sports cars. Data scientists in your office need to work with different algorithms and data in different formats. While they are good at Machine Learning, they count on you to be able to do ETL jobs and build ML pipelines. In this project you will use the modified version of the NASA Airfoil Self Noise dataset. You will clean this dataset, by dropping the duplicate rows, and removing the rows with null values. You will create an ML pipe line to create a model that will predict the SoundLevel based on all the other columns. You will evaluate the model and towards the end you will persist the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this 4 part assignment you will:\n",
    "\n",
    "- Part 1 Perform ETL activity\n",
    "  - Load a csv dataset\n",
    "  - Remove duplicates if any\n",
    "  - Drop rows with null values if any\n",
    "  - Make transformations\n",
    "  - Store the cleaned data in parquet format\n",
    "- Part 2 Create a  Machine Learning Pipeline\n",
    "  - Create a machine learning pipeline for prediction\n",
    "- Part 3 Evaluate the Model\n",
    "  - Evaluate the model using relevant metrics\n",
    "- Part 4 Persist the Model \n",
    "  - Save the model for future production use\n",
    "  - Load and verify the stored model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "In this lab you will be using dataset(s):\n",
    "\n",
    " - The original dataset can be found here NASA airfoil self noise dataset. https://archive.ics.uci.edu/dataset/291/airfoil+self+noise\n",
    " \n",
    " - This dataset is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagram of an airfoil. - For informational purpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Airfoil with flow](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/images/Airfoil_with_flow.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagram showing the Angle of attack. - For informational purpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Airfoil angle of attack](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/images/Airfoil_angle_of_attack.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you Start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before you start attempting this project it is highly recommended that you finish the practice project.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "*   [`PySpark`](https://spark.apache.org/docs/latest/api/python/index.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMSkillsNetworkBD0231ENCoursera2789-2023-01-01) for connecting to the Spark Cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Required Libraries\n",
    "\n",
    "Spark Cluster is pre-installed in the Skills Network Labs environment. However, you need libraries like pyspark and findspark to\n",
    " connect to this cluster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ucimlrepo) (1.3.5)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ucimlrepo) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pandas>=1.0.0->ucimlrepo) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==3.1.2 -q\n",
    "!pip install findspark -q\n",
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "_We recommend you import all required libraries in one place (here):_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FindSpark simplifies the process of using Apache Spark with Python\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Perform ETL activity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Import required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 291, 'name': 'Airfoil Self-Noise', 'repository_url': 'https://archive.ics.uci.edu/dataset/291/airfoil+self+noise', 'data_url': 'https://archive.ics.uci.edu/static/public/291/data.csv', 'abstract': 'NASA data set, obtained from a series of aerodynamic and acoustic tests of two and three-dimensional airfoil blade sections conducted in an anechoic wind tunnel.', 'area': 'Physics and Chemistry', 'tasks': ['Regression'], 'characteristics': ['Multivariate'], 'num_instances': 1503, 'num_features': 5, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['scaled-sound-pressure'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1989, 'last_updated': 'Fri Mar 29 2024', 'dataset_doi': '10.24432/C5VW2C', 'creators': ['Thomas Brooks', 'D. Pope', 'Michael Marcolini'], 'intro_paper': None, 'additional_info': {'summary': 'The NASA data set comprises different size NACA 0012 airfoils at various wind tunnel speeds and angles of attack. The span of the airfoil and the observer position were the same in all of the experiments. ', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'This problem has the following inputs:\\r\\n1. Frequency, in Hertzs. \\r\\n2. Angle of attack, in degrees. \\r\\n3. Chord length, in meters.\\r\\n4. Free-stream velocity, in meters per second. \\r\\n5. Suction side displacement thickness, in meters. \\r\\n\\r\\nThe only output is:\\r\\n6. Scaled sound pressure level, in decibels. \\r\\n', 'citation': None}}\n",
      "                                  name     role        type demographic  \\\n",
      "0                            frequency  Feature     Integer        None   \n",
      "1                         attack-angle  Feature      Binary        None   \n",
      "2                         chord-length  Feature  Continuous        None   \n",
      "3                 free-stream-velocity  Feature  Continuous        None   \n",
      "4  suction-side-displacement-thickness  Feature  Continuous        None   \n",
      "5                scaled-sound-pressure   Target  Continuous        None   \n",
      "\n",
      "  description units missing_values  \n",
      "0        None    Hz             no  \n",
      "1        None   deg             no  \n",
      "2        None     m             no  \n",
      "3        None   m/s             no  \n",
      "4        None     m             no  \n",
      "5        None    dB             no  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "airfoil_self_noise = fetch_ucirepo(id=291) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = airfoil_self_noise.data.features \n",
    "y = airfoil_self_noise.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(airfoil_self_noise.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(airfoil_self_noise.variables) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Create a spark session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/10 20:28:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "#Create a SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Step 1: Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MySparkApplication\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Load the csv file into a dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data file.\n",
    "\n",
    "NOTE : Please ensure you use the dataset below and not the original dataset mentioned above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-10 20:28:13--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/datasets/NASA_airfoil_noise_raw.csv\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104, 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 60682 (59K) [text/csv]\n",
      "Saving to: ‘NASA_airfoil_noise_raw.csv.6’\n",
      "\n",
      "NASA_airfoil_noise_ 100%[===================>]  59.26K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2024-06-10 20:28:13 (39.9 MB/s) - ‘NASA_airfoil_noise_raw.csv.6’ saved [60682/60682]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/datasets/NASA_airfoil_noise_raw.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into the spark dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevel|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "|      800|          0.0|     0.3048|              71.3|             0.00266337|   126.201|\n",
      "|     1000|          0.0|     0.3048|              71.3|             0.00266337|   125.201|\n",
      "|     1250|          0.0|     0.3048|              71.3|             0.00266337|   125.951|\n",
      "|     1600|          0.0|     0.3048|              71.3|             0.00266337|   127.591|\n",
      "|     2000|          0.0|     0.3048|              71.3|             0.00266337|   127.461|\n",
      "|     2500|          0.0|     0.3048|              71.3|             0.00266337|   125.571|\n",
      "|     3150|          0.0|     0.3048|              71.3|             0.00266337|   125.201|\n",
      "|     4000|          0.0|     0.3048|              71.3|             0.00266337|   123.061|\n",
      "|     5000|          0.0|     0.3048|              71.3|             0.00266337|   121.301|\n",
      "|     6300|          0.0|     0.3048|              71.3|             0.00266337|   119.541|\n",
      "|     8000|          0.0|     0.3048|              71.3|             0.00266337|   117.151|\n",
      "|    10000|          0.0|     0.3048|              71.3|             0.00266337|   115.391|\n",
      "|    12500|          0.0|     0.3048|              71.3|             0.00266337|   112.241|\n",
      "|    16000|          0.0|     0.3048|              71.3|             0.00266337|   108.721|\n",
      "|      500|          0.0|     0.3048|              55.5|             0.00283081|   126.416|\n",
      "|      630|          0.0|     0.3048|              55.5|             0.00283081|   127.696|\n",
      "|      800|          0.0|     0.3048|              55.5|             0.00283081|   128.086|\n",
      "|     1000|          0.0|     0.3048|              55.5|             0.00283081|   126.966|\n",
      "|     1250|          0.0|     0.3048|              55.5|             0.00283081|   126.086|\n",
      "|     1600|          0.0|     0.3048|              55.5|             0.00283081|   126.986|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset that you have downloaded in the previous task\n",
    "\n",
    "# Define the correct file path\n",
    "file_path = \"/resources/labs/authoride/IBMSkillsNetwork+BD0231EN/labs/NASA_airfoil_noise_raw.csv\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Print top 5 rows of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevel|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "|      800|          0.0|     0.3048|              71.3|             0.00266337|   126.201|\n",
      "|     1000|          0.0|     0.3048|              71.3|             0.00266337|   125.201|\n",
      "|     1250|          0.0|     0.3048|              71.3|             0.00266337|   125.951|\n",
      "|     1600|          0.0|     0.3048|              71.3|             0.00266337|   127.591|\n",
      "|     2000|          0.0|     0.3048|              71.3|             0.00266337|   127.461|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 - Print the total number of rows in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 1522\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "total_rows = df.count()\n",
    "print(\"Total number of rows:\", total_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 - Drop all the duplicate rows from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=====================================================> (195 + 5) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows after removing duplicates: 1503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Remove duplicates from the DataFrame\n",
    "df_no_duplicates = df.dropDuplicates()\n",
    "\n",
    "# Count the total number of rows after removing duplicates\n",
    "total_rows_no_duplicates = df_no_duplicates.count()\n",
    "\n",
    "# Print the total number of rows after removing duplicates\n",
    "print(\"Total number of rows after removing duplicates:\", total_rows_no_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 - Print the total number of rows in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 1522\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "\n",
    "total_rows = df.count()\n",
    "\n",
    "# Print the total number of rows\n",
    "print(\"Total number of rows:\", total_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 9 - Drop all the rows that contain null values from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Drop rows with any null values\n",
    "df_no_nulls = df.na.drop()\n",
    "\n",
    "# Drop duplicate rows\n",
    "df_no_duplicates = df_no_nulls.dropDuplicates()\n",
    "\n",
    "# Count the total number of rows after dropping null values and duplicates\n",
    "total_rows_no_nulls_duplicates = df_no_duplicates.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10 - Print the total number of rows in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows after dropping null values and duplicates: 1499\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "\n",
    "# Print the total number of rows after dropping null values and duplicates\n",
    "print(\"Total number of rows after dropping null values and duplicates:\", total_rows_no_nulls_duplicates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11 - Rename the column \"SoundLevel\" to \"SoundLevelDecibels\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+------------------+-----------------------+------------------+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevelDecibels|\n",
      "+---------+-------------+-----------+------------------+-----------------------+------------------+\n",
      "|     4000|          3.0|     0.3048|              31.7|             0.00529514|           115.608|\n",
      "|     3150|          2.0|     0.2286|              31.7|             0.00372371|           121.527|\n",
      "|     2000|          7.3|     0.2286|              31.7|              0.0132672|           115.309|\n",
      "|     2000|          5.4|     0.1524|              71.3|             0.00401199|           131.111|\n",
      "|      500|          9.9|     0.1524|              71.3|              0.0193001|           131.279|\n",
      "|     1000|         12.6|     0.1524|              71.3|              0.0483159|           122.044|\n",
      "|    12500|          0.0|     0.0254|              39.6|             4.28464E-4|           129.116|\n",
      "|     1600|          4.8|     0.0254|              39.6|             9.07475E-4|           125.966|\n",
      "|     2000|         15.6|     0.1016|              71.3|              0.0437259|           119.888|\n",
      "|     6300|          0.0|     0.2286|              31.7|              0.0027238|           116.815|\n",
      "|     6300|          2.7|     0.1524|              39.6|             0.00294804|           119.209|\n",
      "|      630|          5.4|     0.1524|              31.7|             0.00525474|           131.471|\n",
      "|      800|         17.4|     0.0254|              31.7|              0.0176631|           139.226|\n",
      "|     2000|          0.0|     0.1016|              31.7|             0.00150092|           133.153|\n",
      "|      200|         15.6|     0.1016|              39.6|              0.0528487|           123.514|\n",
      "|     1000|          0.0|     0.3048|              71.3|             0.00266337|           125.201|\n",
      "|     1250|          0.0|     0.3048|              71.3|             0.00266337|           125.951|\n",
      "|      800|          2.7|     0.1524|              39.6|             0.00294804|           128.829|\n",
      "|     3150|          9.5|     0.0254|              39.6|             0.00449821|           129.934|\n",
      "|     6300|         12.7|     0.0254|              71.3|              0.0121808|           125.398|\n",
      "+---------+-------------+-----------+------------------+-----------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "# Rename the column from \"SoundLevel\" to \"SoundLevelDecibels\"\n",
    "df_renamed = df_no_duplicates.withColumnRenamed(\"SoundLevel\", \"SoundLevelDecibels\")\n",
    "\n",
    "# Show the DataFrame with the renamed column\n",
    "df_renamed.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12 - Save the dataframe in parquet format, name the file as \"NASA_airfoil_noise_cleaned.parquet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Save the DataFrame in Parquet format, overwriting the existing file\n",
    "df_renamed.write.mode(\"overwrite\").parquet(\"NASA_airfoil_noise_cleaned.parquet\")\n",
    "\n",
    "\n",
    "# your code goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 - Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Run the code cell below.**<br>\n",
    "**Use the answers here to answer the final evaluation quiz in the next section.**<br>\n",
    "**If the code throws up any errors, go back and review the code you have written.**</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 - Evaluation\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rowcount1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_72/611915887.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Part 1 - Evaluation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total rows = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowcount1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total rows after dropping duplicate rows = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowcount2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total rows after dropping duplicate rows and rows with null values = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowcount3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rowcount1' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Part 1 - Evaluation\")\n",
    "\n",
    "print(\"Total rows = \", rowcount1)\n",
    "print(\"Total rows after dropping duplicate rows = \", rowcount2)\n",
    "print(\"Total rows after dropping duplicate rows and rows with null values = \", rowcount3)\n",
    "print(\"New column name = \", df.columns[-1])\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"NASA_airfoil_noise_cleaned.parquet exists :\", os.path.isdir(\"NASA_airfoil_noise_cleaned.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part - 2 Create a  Machine Learning Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Load data from \"NASA_airfoil_noise_cleaned.parquet\" into a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "\n",
    "# Load the Parquet file into a DataFrame\n",
    "df_parquet = spark.read.parquet(\"NASA_airfoil_noise_cleaned.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Print the total number of rows in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:==============>                                           (2 + 6) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "\n",
    "rowcount4 = df_parquet.count()\n",
    "print(rowcount4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Define the VectorAssembler pipeline stage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 1 - Assemble the input columns into a single column \"features\". Use all the columns except SoundLevelDecibels as input features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+------------------+-----------------------+------------------+--------------------+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevelDecibels|            features|\n",
      "+---------+-------------+-----------+------------------+-----------------------+------------------+--------------------+\n",
      "|      630|          0.0|     0.3048|              31.7|             0.00331266|           129.095|[630.0,0.0,0.3048...|\n",
      "|     4000|          0.0|     0.3048|              31.7|             0.00331266|           118.145|[4000.0,0.0,0.304...|\n",
      "|     4000|          1.5|     0.3048|              39.6|             0.00392107|           117.741|[4000.0,1.5,0.304...|\n",
      "|      800|          4.0|     0.3048|              71.3|             0.00497773|           131.755|[800.0,4.0,0.3048...|\n",
      "|     1250|          0.0|     0.2286|              31.7|              0.0027238|           128.805|[1250.0,0.0,0.228...|\n",
      "|     2500|          4.0|     0.2286|              55.5|              0.0042862|           122.384|[2500.0,4.0,0.228...|\n",
      "|     1250|          7.3|     0.2286|              71.3|              0.0104404|           127.358|[1250.0,7.3,0.228...|\n",
      "|     2000|         12.6|     0.1524|              71.3|              0.0483159|           117.504|[2000.0,12.6,0.15...|\n",
      "|      800|          8.4|     0.0508|              55.5|             0.00544854|           128.562|[800.0,8.4,0.0508...|\n",
      "|      800|         11.2|     0.0508|              71.3|               0.014072|           136.031|[800.0,11.2,0.050...|\n",
      "|      200|         15.4|     0.0508|              31.7|              0.0289853|           119.975|[200.0,15.4,0.050...|\n",
      "|     4000|         22.2|     0.0254|              71.3|              0.0214178|           123.917|[4000.0,22.2,0.02...|\n",
      "|     5000|          3.3|     0.1016|              71.3|             0.00202822|           127.054|[5000.0,3.3,0.101...|\n",
      "|     1600|          3.3|     0.1016|              55.5|               0.002211|           133.649|[1600.0,3.3,0.101...|\n",
      "|     2500|          3.3|     0.1016|              31.7|             0.00251435|           130.392|[2500.0,3.3,0.101...|\n",
      "|      800|          6.7|     0.1016|              31.7|             0.00592927|           132.886|[800.0,6.7,0.1016...|\n",
      "|     1250|         15.6|     0.1016|              39.6|              0.0528487|           118.214|[1250.0,15.6,0.10...|\n",
      "|      500|          2.0|     0.2286|              71.3|             0.00293031|           126.486|[500.0,2.0,0.2286...|\n",
      "|     2000|          2.0|     0.2286|              39.6|             0.00346574|           122.797|[2000.0,2.0,0.228...|\n",
      "|     4000|          2.0|     0.2286|              31.7|             0.00372371|           120.527|[4000.0,2.0,0.228...|\n",
      "+---------+-------------+-----------+------------------+-----------------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# List of input columns (excluding SoundLevelDecibels)\n",
    "input_columns = [col for col in df_parquet.columns if col != \"SoundLevelDecibels\"]\n",
    "\n",
    "# Initialize VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=input_columns, outputCol=\"features\")\n",
    "\n",
    "# Transform the DataFrame\n",
    "df_assembled = assembler.transform(df_parquet)\n",
    "\n",
    "# Show the DataFrame\n",
    "df_assembled.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Define the StandardScaler pipeline stage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 2 - Scale the \"features\" using standard scaler and store in \"scaledFeatures\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+------------------+-----------------------+------------------+--------------------+--------------------+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevelDecibels|            features|      scaledFeatures|\n",
      "+---------+-------------+-----------+------------------+-----------------------+------------------+--------------------+--------------------+\n",
      "|      630|          0.0|     0.3048|              31.7|             0.00331266|           129.095|[630.0,0.0,0.3048...|[0.19963520038433...|\n",
      "|     4000|          0.0|     0.3048|              31.7|             0.00331266|           118.145|[4000.0,0.0,0.304...|[1.26752508180528...|\n",
      "|     4000|          1.5|     0.3048|              39.6|             0.00392107|           117.741|[4000.0,1.5,0.304...|[1.26752508180528...|\n",
      "|      800|          4.0|     0.3048|              71.3|             0.00497773|           131.755|[800.0,4.0,0.3048...|[0.25350501636105...|\n",
      "|     1250|          0.0|     0.2286|              31.7|              0.0027238|           128.805|[1250.0,0.0,0.228...|[0.39610158806415...|\n",
      "|     2500|          4.0|     0.2286|              55.5|              0.0042862|           122.384|[2500.0,4.0,0.228...|[0.79220317612830...|\n",
      "|     1250|          7.3|     0.2286|              71.3|              0.0104404|           127.358|[1250.0,7.3,0.228...|[0.39610158806415...|\n",
      "|     2000|         12.6|     0.1524|              71.3|              0.0483159|           117.504|[2000.0,12.6,0.15...|[0.63376254090264...|\n",
      "|      800|          8.4|     0.0508|              55.5|             0.00544854|           128.562|[800.0,8.4,0.0508...|[0.25350501636105...|\n",
      "|      800|         11.2|     0.0508|              71.3|               0.014072|           136.031|[800.0,11.2,0.050...|[0.25350501636105...|\n",
      "|      200|         15.4|     0.0508|              31.7|              0.0289853|           119.975|[200.0,15.4,0.050...|[0.06337625409026...|\n",
      "|     4000|         22.2|     0.0254|              71.3|              0.0214178|           123.917|[4000.0,22.2,0.02...|[1.26752508180528...|\n",
      "|     5000|          3.3|     0.1016|              71.3|             0.00202822|           127.054|[5000.0,3.3,0.101...|[1.58440635225661...|\n",
      "|     1600|          3.3|     0.1016|              55.5|               0.002211|           133.649|[1600.0,3.3,0.101...|[0.50701003272211...|\n",
      "|     2500|          3.3|     0.1016|              31.7|             0.00251435|           130.392|[2500.0,3.3,0.101...|[0.79220317612830...|\n",
      "|      800|          6.7|     0.1016|              31.7|             0.00592927|           132.886|[800.0,6.7,0.1016...|[0.25350501636105...|\n",
      "|     1250|         15.6|     0.1016|              39.6|              0.0528487|           118.214|[1250.0,15.6,0.10...|[0.39610158806415...|\n",
      "|      500|          2.0|     0.2286|              71.3|             0.00293031|           126.486|[500.0,2.0,0.2286...|[0.15844063522566...|\n",
      "|     2000|          2.0|     0.2286|              39.6|             0.00346574|           122.797|[2000.0,2.0,0.228...|[0.63376254090264...|\n",
      "|     4000|          2.0|     0.2286|              31.7|             0.00372371|           120.527|[4000.0,2.0,0.228...|[1.26752508180528...|\n",
      "+---------+-------------+-----------+------------------+-----------------------+------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "# Fit the StandardScaler to the data\n",
    "scaler_model = scaler.fit(df_assembled)\n",
    "\n",
    "# Transform the data\n",
    "df_scaled = scaler_model.transform(df_assembled)\n",
    "\n",
    "# Show the DataFrame\n",
    "df_scaled.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 - Define the Model creation pipeline stage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 3 - Create a LinearRegression stage to predict \"SoundLevelDecibels\"\n",
    "\n",
    "**Note:You need to use the scaledfeatures retreived in the previous step(StandardScaler pipeline stage).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/10 20:39:36 WARN util.Instrumentation: [2072220a] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/06/10 20:39:37 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "24/06/10 20:39:37 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "24/06/10 20:39:39 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "24/06/10 20:39:39 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "[Stage 35:>                                                         (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-4.04205014061969,-2.4999359735353774,-3.3413415990555646,1.5607714388511529,-1.9348543216323604]\n",
      "Intercept: 132.82719138025894\n",
      "Root Mean Squared Error: 4.801411\n",
      "R Squared: 0.516196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Define the Linear Regression model\n",
    "lr = LinearRegression(featuresCol='scaledFeatures', labelCol='SoundLevelDecibels')\n",
    "\n",
    "# Fit the model to the data\n",
    "lr_model = lr.fit(df_scaled)\n",
    "\n",
    "# Print the coefficients and intercept\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "training_summary = lr_model.summary\n",
    "print(\"Root Mean Squared Error: %f\" % training_summary.rootMeanSquaredError)\n",
    "print(\"R Squared: %f\" % training_summary.r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 - Build the pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline using the above three stages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"AirfoilSelfNoisePrediction\").getOrCreate()\n",
    "\n",
    "\n",
    "# Rename the column from SoundLevel to SoundLevelDecibels\n",
    "df = df.withColumnRenamed(\"SoundLevel\", \"SoundLevelDecibels\")\n",
    "\n",
    "# Remove rows with null values\n",
    "df = df.dropna()\n",
    "\n",
    "# Define the stages of the pipeline\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Frequency\", \"AngleOfAttack\", \"ChordLength\", \"FreeStreamVelocity\", \"SuctionSideDisplacement\", \"outputCol=\"features\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"scaledFeatures\",\n",
    "    withStd=True,\n",
    "    withMean=False\n",
    ")\n",
    "\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"scaledFeatures\",\n",
    "    labelCol=\"SoundLevelDecibels\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline = Pipeline(stages=[assembler, scaler, lr])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 - Split the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets with 70:30 split.\n",
    "# set the value of seed to 42\n",
    "# the above step is very important. DO NOT set the value of seed to any other value other than 42.\n",
    "\n",
    "#your code goes here\n",
    "\n",
    "(trainingData, testingData) =df.randomSplit([0.7, 0.3], seed=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 - Fit the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/10 20:40:57 WARN util.Instrumentation: [aa06e88b] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline_model = pipeline.fit(trainingData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Run the code cell below.**<br>\n",
    "**Use the answers here to answer the final evaluation quiz in the next section.**<br>\n",
    "**If the code throws up any errors, go back and review the code you have written.**</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2 - Evaluation\n",
      "Total rows =  1499\n",
      "Pipeline Stage 1 =  VectorAssembler\n",
      "Pipeline Stage 2 =  StandardScaler\n",
      "Pipeline Stage 3 =  LinearRegression\n",
      "Label column =  SoundLevelDecibels\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 2 - Evaluation\")\n",
    "print(\"Total rows = \", rowcount4)\n",
    "ps = [str(x).split(\"_\")[0] for x in pipeline.getStages()]\n",
    "\n",
    "print(\"Pipeline Stage 1 = \", ps[0])\n",
    "print(\"Pipeline Stage 2 = \", ps[1])\n",
    "print(\"Pipeline Stage 3 = \", ps[2])\n",
    "\n",
    "print(\"Label column = \", lr.getLabelCol())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Predict using the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/10 20:41:33 WARN util.Instrumentation: [df682d66] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+------------------+-----------------------+------------------+------------------+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevelDecibels|        prediction|\n",
      "+---------+-------------+-----------+------------------+-----------------------+------------------+------------------+\n",
      "|      200|          0.0|     0.3048|              39.6|             0.00310138|           118.129|118.12899999999229|\n",
      "|      200|          7.3|     0.2286|              31.7|              0.0132672|           128.679|128.67900000000606|\n",
      "|      200|          7.3|     0.2286|              39.6|              0.0123481|           130.989|130.98900000000754|\n",
      "|      200|          9.9|     0.1524|              71.3|              0.0193001|           134.319|134.31900000000755|\n",
      "|      200|         12.3|     0.1016|              31.7|              0.0418756|           124.987|124.98700000000537|\n",
      "|      200|         15.6|     0.1016|              39.6|              0.0528487|           123.514|123.51400000000666|\n",
      "|      200|         15.6|     0.1016|              71.3|              0.0437259|           130.898|130.89800000000938|\n",
      "|      200|         17.4|     0.0254|              31.7|              0.0176631|           116.146|116.14599999998941|\n",
      "|      200|         19.7|     0.0508|              71.3|              0.0341183|           118.005|118.00499999999302|\n",
      "|      200|         22.2|     0.0254|              39.6|              0.0229028|           116.066|116.06599999999139|\n",
      "|      250|          9.5|     0.0254|              39.6|             0.00449821|           116.924|116.92399999998389|\n",
      "|      250|          9.9|     0.1524|              31.7|              0.0252785|           128.559|128.55900000000665|\n",
      "|      250|          9.9|     0.1524|              55.5|              0.0208438|           133.235|133.23500000000834|\n",
      "|      250|         11.2|     0.0508|              39.6|              0.0150478|            126.43| 126.4299999999979|\n",
      "|      250|         12.3|     0.1016|              55.5|              0.0368233|           133.294|133.29400000001087|\n",
      "|      250|         12.7|     0.0254|              39.6|              0.0130253|           121.547|121.54699999999181|\n",
      "|      250|         15.4|     0.0508|              31.7|              0.0289853|           121.225|121.22499999999768|\n",
      "|      250|         15.4|     0.0508|              71.3|              0.0264269|           124.835|124.83499999999714|\n",
      "|      250|         19.7|     0.0508|              39.6|               0.036484|           127.224|127.22400000000644|\n",
      "|      315|          0.0|     0.3048|              31.7|             0.00331266|           122.765|122.76499999999815|\n",
      "+---------+-------------+-----------+------------------+-----------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline using the training data\n",
    "pipeline_model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = pipeline_model.transform(testingData)\n",
    "\n",
    "# Show the predictions\n",
    "predictions.select(\"Frequency\", \"AngleOfAttack\", \"ChordLength\", \"FreeStreamVelocity\", \"SuctionSideDisplacement\", \"SoundLevelDecibels\", \"prediction\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Print the MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on test data = 2.445646531627305e-23\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using Mean Squared Error (MSE)\n",
    "evaluator = RegressionEvaluator(labelCol=\"SoundLevelDecibels\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE) on test data = {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Print the MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on test data = 3.8051473561071e-12\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Evaluate the model using Mean Absolute Error (MAE)\n",
    "evaluator = RegressionEvaluator(labelCol=\"SoundLevelDecibels\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE) on test data = {mae}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Print the R-Squared(R2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (R2) on test data = 1.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Evaluate the model using R-squared (R2)\n",
    "evaluator = RegressionEvaluator(labelCol=\"SoundLevelDecibels\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"R-squared (R2) on test data = {r2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 - Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Run the code cell below.**<br>\n",
    "**Use the answers here to answer the final evaluation quiz in the next section.**<br>\n",
    "**If the code throws up any errors, go back and review the code you have written.**</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3 - Evaluation\n",
      "Mean Squared Error =  0.0\n",
      "Mean Absolute Error =  0.0\n",
      "R Squared =  1.0\n",
      "Intercept =  -0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 3 - Evaluation\")\n",
    "\n",
    "print(\"Mean Squared Error = \", round(mse,2))\n",
    "print(\"Mean Absolute Error = \", round(mae,2))\n",
    "print(\"R Squared = \", round(r2,2))\n",
    "\n",
    "lrModel = pipeline_model.stages[-1]\n",
    "\n",
    "print(\"Intercept = \", round(lrModel.intercept,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Persist the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Save the model to the path \"Final_Project\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save the pipeline model as \"Final_Project\"\n",
    "# your code goes here\n",
    "# Save the trained pipeline model\n",
    "pipeline_model.write().overwrite().save(\"Final Project\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Load the model from the path \"Final_Project\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the pipeline model you have created in the previous step\n",
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "# Load the saved pipeline model\n",
    "loaded_pipeline_model = PipelineModel.load(\"Final Project\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Make predictions using the loaded model on the testdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the loaded pipeline model and make predictions using testingData\n",
    "\n",
    "# Make predictions on the test data using the loaded model\n",
    "predictions_loaded_model = loaded_pipeline_model.transform(testingData)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Show the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+------------------+-----------------------+------------------+------------------+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevelDecibels|        prediction|\n",
      "+---------+-------------+-----------+------------------+-----------------------+------------------+------------------+\n",
      "|      200|          0.0|     0.3048|              39.6|             0.00310138|           118.129|118.12899999999229|\n",
      "|      200|          7.3|     0.2286|              31.7|              0.0132672|           128.679|128.67900000000606|\n",
      "|      200|          7.3|     0.2286|              39.6|              0.0123481|           130.989|130.98900000000754|\n",
      "|      200|          9.9|     0.1524|              71.3|              0.0193001|           134.319|134.31900000000755|\n",
      "|      200|         12.3|     0.1016|              31.7|              0.0418756|           124.987|124.98700000000537|\n",
      "+---------+-------------+-----------+------------------+-----------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Show the predictions\n",
    "predictions_loaded_model.select(\"Frequency\", \"AngleOfAttack\", \"ChordLength\", \"FreeStreamVelocity\", \"SuctionSideDisplacement\", \"SoundLevelDecibels\", \"prediction\").show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 - Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Run the code cell below.**<br>\n",
    "**Use the answers here to answer the final evaluation quiz in the next section.**<br>\n",
    "**If the code throws up any errors, go back and review the code you have written.**</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 4 - Evaluation\n",
      "Number of stages in the pipeline =  3\n",
      "Coefficient for Frequency is 0.0\n",
      "Coefficient for AngleOfAttack is 0.0\n",
      "Coefficient for ChordLength is 0.0\n",
      "Coefficient for FreeStreamVelocity is -0.0\n",
      "Coefficient for SuctionSideDisplacement is 0.0\n",
      "Coefficient for SoundLevelDecibels is 7.0395\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 4 - Evaluation\")\n",
    "\n",
    "loadedmodel = loaded_pipeline_model.stages[-1]\n",
    "totalstages = len(loaded_pipeline_model.stages)\n",
    "inputcolumns = loaded_pipeline_model.stages[0].getInputCols()\n",
    "\n",
    "print(\"Number of stages in the pipeline = \", totalstages)\n",
    "for i,j in zip(inputcolumns, loadedmodel.coefficients):\n",
    "    print(f\"Coefficient for {i} is {round(j,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ramesh Sannareddy](https://www.linkedin.com/in/rsannareddy/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMBD0231ENSkillsNetwork866-2023-01-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2023-05-26|0.1|Ramesh Sannareddy|Initial Version Created|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2023 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "prev_pub_hash": "7f2fb6b481a4fe3bc99b856722dc389d1754d5fd0bee488552bdf9a9d6e8cf82"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
